{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A \"Hello World\" Example of Machine Learning - Revisit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Iris dataset from scikit-learn. \n",
    "\n",
    "The first column represents Sepal length, the second column represents Sepal width,  the third column represents the petal length, and the fourth column the petal width of the flower samples. The classes (type of species) are already converted to integer labels where 0=Iris-Setosa, 1=Iris-Versicolor, 2=Iris-Virginica.\n",
    "\n",
    "Here, we are using only two features: the third and fourth columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, [0, 3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Class labels: [0 1 2]\n"
    }
   ],
   "source": [
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn algorithms support multi-class classification via the One-Versus-Rest(OvR) method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into 70% training and 30% test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Labels counts in y: [50 50 50]\nLabels counts in y_train: [35 35 35]\nLabels counts in y_test: [15 15 15]\n"
    }
   ],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Perceptron(eta0=0.1, max_iter=100, random_state=42)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(max_iter=100, eta0=0.1, random_state=42)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model with the hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Misclassified samples: 10\n"
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy: 0.7777777777777778\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([2, 2, 2])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = [[1.1, 0.2],[0.4, 1.9], [1.4, 0.2]]\n",
    "y_new = ppn.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.88888889, 0.76923077, 0.53846154, 0.80769231])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ppn, X_train_std, y_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-features: sccuracy score: array([0.88888889, 0.48148148, 0.7037037 , 0.95833333])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Use all four features to train the model and use cross validaton to check if the results better? Briefly explain why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Misclassified samples: 3\nAccuracy: 0.9333333333333333\n"
    },
    {
     "data": {
      "text/plain": "array([0.92592593, 0.88461538, 0.84615385, 0.88461538])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = iris.data[:]\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
    "    X1, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "sc.fit(X1_train)\n",
    "X1_train_std = sc.transform(X1_train)\n",
    "X1_test_std = sc.transform(X1_test)\n",
    "\n",
    "ppn.fit(X1_train_std, y1_train)\n",
    "y1_pred = ppn.predict(X1_test_std)\n",
    "print('Misclassified samples: ' + str((y1_test != y1_pred).sum()))\n",
    "print('Accuracy: ' + str(accuracy_score(y1_test, y1_pred)))\n",
    "\n",
    "cross_val_score(ppn, X1_train_std, y1_train, cv=4, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Try with the scikit-learn stochastic gradient descent model instead of perceptron. Use all four features. Evaluate with cross-validation how does the model perform in terms of accuracy using both two features and four features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Misclassified samples: 1\nAccuracy: 0.9777777777777777\nMisclassified samples: 5\nAccuracy: 0.8888888888888888\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "\n",
    "sgd.fit(X_train_std, y_train)\n",
    "y_pred = sgd.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "sgd.fit(X1_train_std, y1_train)\n",
    "y_pred = sgd.predict(X1_test_std)\n",
    "print('Misclassified samples: ' + str((y1_test != y_pred).sum()))\n",
    "print('Accuracy: ' + str(accuracy_score(y1_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With the perceptron model, switching from 2 to 4 features has improved the model accuracy, but with the stochastic gradient descent model the accuracy was better using 2 features instead of 4 features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}